{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mine: Question4_MLSP_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Image Data "
      ],
      "metadata": {
        "id": "6nYAM4XOkC8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysiaWZStIEvF",
        "outputId": "7e6464a4-658d-4d63-cd6e-05cdafd797e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading all the training data as 100x100 images"
      ],
      "metadata": {
        "id": "uv0Ls33LkHvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from PIL import *\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "happ_loc=['01','02','04','06','07','09','10','12','13']\n",
        "sad_loc=['02','03','04','05','06','07','09','10','11','12','13']\n",
        "happy_images = []\n",
        "for i in happ_loc:\n",
        "  loc='drive/MyDrive/Data/emotion_classification/train/subject'+i+'.happy.gif'\n",
        "  img=Image.open(loc)\n",
        "  img1=img.resize((100,100))\n",
        "  img_arr=np.array(img1)\n",
        "  img_arr=img_arr.reshape(10000,)\n",
        "  happy_images.append(img_arr)\n",
        "happyImages=np.array(happy_images)\n",
        "sad_images = []\n",
        "for i in sad_loc:\n",
        "  loc='drive/MyDrive/Data/emotion_classification/train/subject'+i+'.sad.gif'\n",
        "  img=Image.open(loc)\n",
        "  img1=img.resize((100,100))\n",
        "  img_arr=np.array(img1)\n",
        "  img_arr=img_arr.reshape(10000,)\n",
        "  sad_images.append(img_arr)\n",
        "sadImages=np.array(sad_images)"
      ],
      "metadata": {
        "id": "_0v6hJ1aih82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing the images, calculating sample covarince matrix and eigenvalue, eigenvectors for it"
      ],
      "metadata": {
        "id": "yNy2uTcgkzIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "happyImages = happyImages/255\n",
        "sadImages = sadImages/255\n",
        "temp1=[]\n",
        "for i in happyImages:\n",
        "  temp1.append(i)\n",
        "for i in sadImages:\n",
        "  temp1.append(i)\n",
        "X=np.array(temp1)\n",
        "X=np.transpose(X)\n",
        "Xm = X.mean(axis=1)\n",
        "Xm = np.reshape(Xm, (10000,1))\n",
        "N=20\n",
        "Sx = np.dot(np.transpose(X - Xm), (X - Xm))/N\n",
        "lambda_all, V_all = np.linalg.eigh(Sx)"
      ],
      "metadata": {
        "id": "B6ZywKuDkydh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing PCA for higher dimension to reduce running time and for efficincy. K=18 gives the best separation as seen by plotting the projection on LDA."
      ],
      "metadata": {
        "id": "2Cu0zlMEIWed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.argsort(lambda_all)\n",
        "idx=idx[::-1]\n",
        "lambdas = lambda_all[idx]\n",
        "V = V_all[:,idx]\n",
        "k = 18  \n",
        "V_PCA = V[:,0:k] "
      ],
      "metadata": {
        "id": "Tnw5XwXogqwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting lower dimension eigenvectors to higher dimension(dimension of feature vector)"
      ],
      "metadata": {
        "id": "Pe6sdyFIJ_O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "U = np.zeros((10000,1)) \n",
        "index = 0\n",
        "for v in np.transpose(V_PCA):\n",
        "  x = v.reshape((20,1))\n",
        "  den = math.sqrt(abs(lambdas[index]*20))\n",
        "  u = np.dot(X,x)/den\n",
        "  U = np.append(U,u,axis = 1)\n",
        "  index += 1\n",
        "U = np.array(U) \n",
        "U = U[:,1:]"
      ],
      "metadata": {
        "id": "WAAwxmYzJMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying PCA on happy images and sad images"
      ],
      "metadata": {
        "id": "IqntHrRaKxjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "happyImages=np.transpose(happyImages)\n",
        "sadImages=np.transpose(sadImages)\n",
        "PCA_Happy = np.dot(U.T, happyImages)\n",
        "PCA_Sad = np.dot(U.T, sadImages)\n",
        "Xm_Happy = PCA_Happy.mean(axis=1)\n",
        "Xm_Sad = PCA_Sad.mean(axis=1)\n",
        "Xm_Happy = np.reshape(Xm_Happy,(k,1))\n",
        "Xm_Sad = np.reshape(Xm_Sad,(k,1))"
      ],
      "metadata": {
        "id": "32AGvLiy4Yse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing LDA on images after PCA. Calculating between class covarince mtrix and within class covarince matrix"
      ],
      "metadata": {
        "id": "fyKEqWAfLHGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Sb = np.dot((Xm_Happy - Xm_Sad), (Xm_Happy.T - Xm_Sad.T))\n",
        "Sw = np.dot((PCA_Happy - Xm_Happy), np.transpose(PCA_Happy - Xm_Happy))/9 + np.dot((PCA_Sad - Xm_Sad), np.transpose(PCA_Sad - Xm_Sad))/11\n",
        "Swinv = np.linalg.inv(Sw)"
      ],
      "metadata": {
        "id": "IVsNmG9LB-Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding W for maximum fisher ratio solution"
      ],
      "metadata": {
        "id": "xTFPz8LpMczV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_LDA_temp, W_temp = np.linalg.eigh(np.dot(Swinv, Sb))\n",
        "idx = lambda_LDA_temp.argsort()[::-1]\n",
        "sorted_Lambda_LDA = lambda_LDA_temp[idx]\n",
        "sorted_W = W_temp[:, idx]\n",
        "W = sorted_W[:,0]\n",
        "W = W.reshape((k,1))"
      ],
      "metadata": {
        "id": "3t9RMSD8DhPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the projected LDA data on 1 dimension and checking the class separation "
      ],
      "metadata": {
        "id": "wup1KuhGNXLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Happy_proj = np.dot(np.transpose(W), PCA_Happy)\n",
        "Sad_proj = np.dot(np.transpose(W), PCA_Sad)\n",
        "plt.scatter(Happy_proj ,np.zeros((9,), dtype = int),color = 'b') \n",
        "plt.scatter(Sad_proj ,np.zeros((11,),dtype = int), color = 'r') \n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "985hMCFf_YfL",
        "outputId": "7437c389-0cba-4264-81c8-43e8d89e2742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see K=18 gives very good separatibility. Separatibility scatter plot for K=5,10,15,17,18,20 is attached at question end."
      ],
      "metadata": {
        "id": "eyon1e-tEzfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the test data images"
      ],
      "metadata": {
        "id": "4qLfifa0NhnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_happ_loc=['03','05','08','11','14','15']\n",
        "test_sad_loc=['01','08','14','15']\n",
        "test_images = []\n",
        "for i in test_happ_loc:\n",
        "  loc='drive/MyDrive/Data/emotion_classification/test/subject'+i+'.happy.gif'\n",
        "  img=Image.open(loc)\n",
        "  img1=img.resize((100,100))\n",
        "  img_arr=np.array(img1)\n",
        "  img_arr=img_arr.reshape(10000,)\n",
        "  test_images.append(img_arr)\n",
        "for i in test_sad_loc:\n",
        "  loc='drive/MyDrive/Data/emotion_classification/test/subject'+i+'.sad.gif'\n",
        "  img=Image.open(loc)\n",
        "  img1=img.resize((100,100))\n",
        "  img_arr=np.array(img1)\n",
        "  img_arr=img_arr.reshape(10000,)\n",
        "  test_images.append(img_arr)\n",
        "testImages=np.array(test_images)\n",
        "testImages = np.array(test_images)/255\n",
        "testImages = np.transpose(testImages)\n",
        "print(testImages.shape)\n",
        "print(U.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1LxhYl5Hgn7",
        "outputId": "aade95ef-1191-4a5c-c940-21c864eeaecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 10)\n",
            "(10000, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing PCA and LDA on test images and checking the classification accuracy. 100% classification accuracy achived for k=18. Classification accuracy of 100% achived using suitable separation point (val=0.8) on LDA projection. "
      ],
      "metadata": {
        "id": "-QGXgDUwNpk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_test_images = np.dot(U.T, testImages)\n",
        "LDA_test_images = np.dot(W.T, PCA_test_images)\n",
        "index = 0\n",
        "for element in LDA_test_images.T:\n",
        "  index += 1 \n",
        "  if element >= 0.8:\n",
        "    print(f\"{index} is SAD \",end=\"\")\n",
        "    # sad_pred.append(element) \n",
        "  else :\n",
        "    print(f\"{index} is HAPPY \",end=\"\")\n",
        "    # happy_pred.append(element)\n",
        "  if index <= 6: # first 5 row-vectors are form HAPPy images\n",
        "    print(\",Actual status = HAPPY\") \n",
        "  else:\n",
        "    print(\",Actual status = SAD\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD6OUEwQJyla",
        "outputId": "914921ea-6323-469a-861b-4f906440255f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 is HAPPY ,Actual status = HAPPY\n",
            "2 is HAPPY ,Actual status = HAPPY\n",
            "3 is HAPPY ,Actual status = HAPPY\n",
            "4 is HAPPY ,Actual status = HAPPY\n",
            "5 is HAPPY ,Actual status = HAPPY\n",
            "6 is HAPPY ,Actual status = HAPPY\n",
            "7 is SAD ,Actual status = SAD\n",
            "8 is SAD ,Actual status = SAD\n",
            "9 is SAD ,Actual status = SAD\n",
            "10 is SAD ,Actual status = SAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using K=18 and threshold value of 0.8 gave best resuls on data set. Even, K=15 and threshold = 0.6 gives 100% accurate resuls.\n",
        "\n",
        "Increasing K further also leads to increase in within class variance thus reducing the accuracy of separation as can be seen below. Because of high within class varince the data begins to overlap instead of separating. "
      ],
      "metadata": {
        "id": "oYleu2sxFI7s"
      }
    }
  ]
}